# America's Racial Framework of Superiority and Americanness Embedded in Natural Language

Paper and related materials for [Lee](https://lee-messi.github.io/), [Montgomery](https://sites.wustl.edu/montgomery/), and [Lai](https://sites.wustl.edu/calvinlai/) (submitted). The abstract for the paper is as follows:

> America’s racial framework can be summarized using two distinct dimensions: superiority/inferiority and Americanness/foreignness (Zou & Cheryan, 2017). We investigated America’s racial framework in a corpus of spoken and written language using word embeddings. Word embeddings place words on a low-dimensional space where words with similar meanings are proximate, allowing researchers to test whether the positions of group and attribute words in a semantic space reﬂect stereotypes. We trained a word embedding model on the Corpus of Contemporary American English - a corpus of one-billion words that span thirty years and eight text categories - and compared the positions of racial/ethnic groups with respect to superiority and Americanness. We found that America’s racial framework is embedded in American English. We also captured an additional nuance: Asian people were stereotyped as more American than Hispanic people. These results are empirical evidence that America’s racial framework is embedded in American English.

This paper has been submitted, but comments are still very welcome. Please feel free to send us an [email](mailto:hojunlee@wustl.edu), or open an "Issue" here. For detailed instructions for reproducing analysis, refer to the [Instructions.md](Instructions.md) document.

## Data Availability Statement

This repository does not include all data files. First, data files containing the trained word embedding model are not part of this repository because their file sizes are greater than the Github storage limit. You can access these files via our [OSF repository](https://osf.io/n5xyk/?view_only=ffd4adcfedb84deda7282ccf19bc3aac). Second, data files containing the Corpus of Contemporary American English (COCA) are not part of this repository because the corpus is proprietary and must be purchased separately (https://www.english-corpora.org/coca/). However, we have made it so that you can reproduce the analyses without access to COCA. For detailed instructions for reproducing analyses, refer to the Instructions document [here](Instructions.md). 

